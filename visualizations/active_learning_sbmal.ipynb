{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import floor, ceil, sqrt\n",
    "\n",
    "############### PARAMS ##################\n",
    "tag = \"sbmal_3_balanced_val[0]_v3\"\n",
    "only_compare = [] # ['FIXED [0]', 'EPIST PROP', 'RANDOM', 'FIXED [3]', 'FIXED [5]']\n",
    "#########################################\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "\"\"\"\n",
    "https://stackoverflow.com/questions/21654635/scatter-plots-in-pandas-pyplot-how-to-plot-by-category\n",
    "\"\"\"\n",
    "\n",
    "def afterPoint(str):\n",
    "    return str.split('.')[-1]\n",
    "\n",
    "def getKey(str):\n",
    "    if str == 'FINAL':\n",
    "        return 99999999\n",
    "    elif str == 'BASELINE':\n",
    "        return 1\n",
    "    else:\n",
    "        return int(str)\n",
    "    \n",
    "def getKeyName(name):\n",
    "    names = {\n",
    "        'ALEA ISO': 4, \n",
    "        'ALEA PROP': 3, \n",
    "        'EPIST ISO': 2, \n",
    "        'EPIST PROP': 1, \n",
    "        'L2_DISTANCE': 5, \n",
    "        'RANDOM': 6, \n",
    "        'FIXED [0, 1, 2, 3]': 7,\n",
    "        'FIXED [0]': 12,\n",
    "        'FIXED [1]': 11,\n",
    "        'FIXED [2]': 10,\n",
    "        'FIXED [3]': 9,\n",
    "        'FIXED [4]': 8,\n",
    "        'FIXED [5]': 7.5\n",
    "    }\n",
    "    return names[name]\n",
    "        \n",
    "    \n",
    "def sortBy(datapoints):\n",
    "    datapoints.sort(key=lambda datapoint: getKey(datapoint['timestep']) * 1000 + getKeyName(datapoint['selector']))\n",
    "    \n",
    "def getColumn(datapoints, column):\n",
    "    return list(map(lambda x: x[column], datapoints))\n",
    "    \n",
    "    \n",
    "def getSelectorName(run):\n",
    "    active_learning_selector = afterPoint(run.config[\"experiment/active_learning_selector\"])\n",
    "    if active_learning_selector == \"UNCERTAINTY\":\n",
    "        uncertainty_name = \"ALEA\" if afterPoint(run.config['experiment/active_learning_selector_uncertainty_mode']) == 'ALEATORIC' else 'EPIST'\n",
    "        prop_name = 'ISO' if afterPoint(run.config['experiment/active_learning_selector_network_mode']) == 'ISOLATED' else 'PROP'\n",
    "        active_learning_selector = f\"{uncertainty_name} {prop_name}\"\n",
    "    elif active_learning_selector == \"FIXED\":\n",
    "        prop_name = run.config['experiment/active_learning_training_type']\n",
    "        active_learning_selector = f\"{active_learning_selector} {prop_name}\"\n",
    "        \n",
    "    return active_learning_selector\n",
    "\n",
    "SUMMARY_FINAL_ACCURACY = '/eval/VALTEST/PROPAGATED/accuracy'\n",
    "AL_PREFIX = 'mean/al/'\n",
    "AL_SUFFIX = '/VALTEST/PROPAGATED/accuracy'\n",
    "\n",
    "api = wandb.Api(timeout=100)\n",
    "runs = api.runs(\"tum_daml_ba_antoniooroz/GR2\", {\"tags\" : tag})\n",
    "\n",
    "runs_per_model = {}\n",
    "\n",
    "for run in runs:\n",
    "    if run.config[\"debug\"] or run.state != 'finished':\n",
    "        continue\n",
    "    \n",
    "    model_type = str(run.config[\"model/type\"])\n",
    "    \n",
    "    if model_type in runs_per_model:\n",
    "        runs_per_model[model_type].append(run)\n",
    "    else:\n",
    "        runs_per_model[model_type] = [run]\n",
    "        \n",
    "for key, runs in runs_per_model.items():\n",
    "    datapoints = []\n",
    "    SAMPLES = (run.config['experiment/seeds/end'] - run.config['experiment/seeds/start']) * run.config['experiment/iterations_per_seed']\n",
    "    \n",
    "    for run in runs:\n",
    "        model = afterPoint(run.config[\"model/type\"])\n",
    "        \n",
    "        #if run.config['experiment/active_learning_l2_distance_use_centroids']==True and afterPoint(run.config['experiment/active_learning_selector'])=='L2_DISTANCE':\n",
    "        #    continue\n",
    "    \n",
    "        active_learning_selector = getSelectorName(run)\n",
    "        \n",
    "        if len(only_compare) > 0 and active_learning_selector not in only_compare:\n",
    "            continue\n",
    "\n",
    "        for summary_key, summary_value in run.summary.items():\n",
    "            if summary_key.startswith(AL_PREFIX) and summary_key.endswith(AL_SUFFIX):\n",
    "                num = summary_key.replace(AL_PREFIX, '').replace(AL_SUFFIX, '')\n",
    "                \n",
    "                if num == '1':\n",
    "                    continue\n",
    "                \n",
    "                datapoints.append({\n",
    "                    'accuracy': summary_value*100,\n",
    "                    'deviation': run.summary[summary_key.replace('mean/', 'std/', 1)]*100,\n",
    "                    'error': run.summary[summary_key.replace('mean/', 'std/', 1)]*100/sqrt((SAMPLES)),\n",
    "                    '95-confidence': run.summary[f\"std{SUMMARY_FINAL_ACCURACY}\"]*100/sqrt((SAMPLES))*1.95964,\n",
    "                    'max': run.summary[summary_key.replace('mean/', 'max/', 1)]*100,\n",
    "                    'min': run.summary[summary_key.replace('mean/', 'min/', 1)]*100,\n",
    "                    'timestep': num,\n",
    "                    'selector': active_learning_selector\n",
    "                })\n",
    "        datapoints.append({\n",
    "            'accuracy': run.summary[f\"mean{SUMMARY_FINAL_ACCURACY}\"]*100,\n",
    "            'deviation': run.summary[f\"std{SUMMARY_FINAL_ACCURACY}\"]*100,\n",
    "            'error': run.summary[f\"std{SUMMARY_FINAL_ACCURACY}\"]*100/sqrt((SAMPLES)),\n",
    "            '95-confidence': run.summary[f\"std{SUMMARY_FINAL_ACCURACY}\"]*100/sqrt((SAMPLES))*1.95964,\n",
    "            'max': run.summary[f\"max{SUMMARY_FINAL_ACCURACY}\"]*100,\n",
    "            'min': run.summary[f\"min{SUMMARY_FINAL_ACCURACY}\"]*100,\n",
    "            'timestep': 'FINAL',\n",
    "            'selector': active_learning_selector\n",
    "        })\n",
    "        \n",
    "    sortBy(datapoints)\n",
    "        \n",
    "    df = pd.DataFrame(dict(\n",
    "        x=getColumn(datapoints, 'timestep'), \n",
    "        y=getColumn(datapoints, 'accuracy'), \n",
    "        err=getColumn(datapoints, 'deviation'), \n",
    "        label=getColumn(datapoints, 'selector'), \n",
    "        minimum=getColumn(datapoints, 'min'),\n",
    "        maximum=getColumn(datapoints, 'max')))\n",
    "    groups = df.groupby('label')\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 4), dpi=200)\n",
    "    ax.margins(0.05)\n",
    "    for name, group in groups:\n",
    "        ax.set_ylim([0.0, 100])\n",
    "        ax.plot(group.x, group.y, '-', label=name, zorder=10)\n",
    "        ax.fill_between(group.x, group.y-group.err, group.y+group.err, label=f\"_{name}\", alpha=0.2, zorder=0)\n",
    "        #ax.fill_between(group.x, group.minimum, group.maximum, label=f\"_{name}\", alpha=0.2, zorder=0)\n",
    "        ax.yaxis.set_ticks(np.arange(0, 105, 5))\n",
    "    \n",
    "    ax.legend(fontsize = 'xx-small')\n",
    "    plt.title(key)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pgnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "653f79a9a30ff5fc1d7d9f0f9422fa69580dec5fab360a1400dfddff94dae4ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
